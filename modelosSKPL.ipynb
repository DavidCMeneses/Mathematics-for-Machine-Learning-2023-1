{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "heKZwNin8WgA",
        "n22k4AEm8oID",
        "8BQvnNB__X0O",
        "N_u94ncXENWx",
        "hxvGTgeBG3sP"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "_BJuLLdlqOag"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PfHD9MLEo5nS"
      },
      "outputs": [],
      "source": [
        "# Other imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statistics as st\n",
        "import urllib\n",
        "import zipfile\n",
        "\n",
        "# Scikit learn\n",
        "from sklearn import svm\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Datasets"
      ],
      "metadata": {
        "id": "9qxwaRZeqUKt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a cargar los Datasets del primer ejercicio de SVM, para resumir un poco el contenido de estos tenemos que recordar el problema que se desea solucionar. En ambos casos tenemos un problema de clasificación binario, en el primer Dataset debemos identificar billetes falsos. En el segundo Dataset debemos poder afirmar si una oficina se encuentra ocupada o no.\n",
        "\n",
        "Los atributos del primer Dataset son varianza, skewness, curtosis y entropía.\n",
        "\n",
        "Los atributos del segundo Dataset son fecha, temperatura, humedad, luz, cantidad de CO2 y la razón de la humedad."
      ],
      "metadata": {
        "id": "EpsrlzQw5EiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos y organizamos el primer Dataset\n",
        "data_bank = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt', header=None)\n",
        "data_bank.columns = [\"variance\", \"skewness\", \"curtosis\", \"entropy\", \"class\"]\n",
        "\n",
        "# Remplazamos los 0 por -1 para los modelos\n",
        "data_bank[\"class\"] = data_bank[\"class\"].replace([0],-1)\n",
        "\n",
        "# Separamos los atributos de las etiquetas\n",
        "X_data_bank = data_bank[[\"variance\", \"skewness\", \"curtosis\", \"entropy\"]]\n",
        "y_data_bank = data_bank[\"class\"]"
      ],
      "metadata": {
        "id": "sinxsvNapU7P"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargamos y descomprimos el segundo Dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00357/occupancy_data.zip\"\n",
        "extract_dir = \"occupancy\"\n",
        "\n",
        "# Descomprimimos el zip\n",
        "zip_path, _ = urllib.request.urlretrieve(url)\n",
        "with zipfile.ZipFile(zip_path, \"r\") as f:\n",
        "    f.extractall(extract_dir)"
      ],
      "metadata": {
        "id": "JIBNSkTdpWr8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def occupancy_df_process(path):\n",
        "  data = pd.read_csv(path, sep=\",\", \n",
        "            names=[\"col\",\"date\",\"Temperature\",\"Humidity\",\"Light\",\"CO2\",\"HumidityRatio\",\"Occupancy\"])[1:]\n",
        "\n",
        "  data = data.drop([\"col\"],axis=1)\n",
        "  # Casteamo todo a float\n",
        "  data[\"Light\"] = data[\"Light\"].astype(float)\n",
        "  data[\"Temperature\"] = data[\"Temperature\"].astype(float)\n",
        "  data[\"Humidity\"] = data[\"Humidity\"].astype(float)\n",
        "  data[\"CO2\"] = data[\"CO2\"].astype(float)\n",
        "  data[\"HumidityRatio\"] = data[\"HumidityRatio\"].astype(float)\n",
        "  data[\"Occupancy\"] = data[\"Occupancy\"].astype(float)\n",
        "\n",
        "\n",
        "  # Remplazamos los 0 por -1 para los modelos\n",
        "  data[\"Occupancy\"] = data[\"Occupancy\"].replace([0],-1)\n",
        "\n",
        "  # Separamos los atributos de las etiquetas\n",
        "  X_data = data[[\"Temperature\",\"Humidity\",\"Light\",\"CO2\",\"HumidityRatio\"]]\n",
        "  Y_data = data[\"Occupancy\"]\n",
        "  return X_data, Y_data\n",
        "\n",
        "occupancy_train_X , occupancy_train_y = occupancy_df_process(\"occupancy/datatraining.txt\")\n",
        "occupancy_test_X , occupancy_test_y = occupancy_df_process(\"occupancy/datatest.txt\")\n",
        "occupancy_test2_X , occupancy_test2_y = occupancy_df_process(\"occupancy/datatest2.txt\")\n",
        "\n",
        "# Juntamos los dataframes en uno único\n",
        "occupancy_X = pd.concat([occupancy_train_X,occupancy_test_X, occupancy_test2_X])\n",
        "occupancy_y = pd.concat([occupancy_train_y, occupancy_test_y, occupancy_test2_y])"
      ],
      "metadata": {
        "id": "USHmkBxqp0WF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelos para el primer Dataset"
      ],
      "metadata": {
        "id": "T54hqK8Ax7oS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM"
      ],
      "metadata": {
        "id": "heKZwNin8WgA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para el modelo de support vector machine contamos con el hiperparametro de regulación C, el kernel utilizado en el algoritmo, y un parametro que baraja los datos de forma aleatoria. \n",
        "\n",
        "Para elegir el mejor valor de \"C\" se utilizó prueba y error, buscano entre los enteros del 1 al 9.\n",
        "\n",
        "En el caso del kernel, el algoritmo con el mejor rendimiento fue \"RBF\" que es una función de base radial utilizada para transformar los datos en un espacio dimensional superior, donde es más probable que los datos sean linealmente separables. La función RBF calcula la similitud entre dos puntos en función de su distancia radial."
      ],
      "metadata": {
        "id": "w8m__xtx6xlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sup = svm.SVC(kernel='linear', C=1, random_state=42)\n",
        "scores = cross_val_score(sup, X_data_bank, y_data_bank, cv=20)\n",
        "print(\"Rendimiento en cross val:\", scores)\n",
        "print(\"Rendimiento overall:\", st.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XimjiU998qqn",
        "outputId": "203c02d8-b2ee-4195-eca8-7dfda5b4392f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rendimiento en cross val: [0.97101449 1.         1.         0.98550725 0.98550725 0.97101449\n",
            " 1.         0.98550725 0.97101449 0.97101449 0.98550725 0.98550725\n",
            " 1.         1.         1.         1.         1.         0.98529412\n",
            " 0.98529412 0.98529412]\n",
            "Rendimiento overall: 0.9883738277919863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sup = svm.SVC(kernel='poly', C=2, random_state=42)\n",
        "scores = cross_val_score(sup, X_data_bank, y_data_bank, cv=20)\n",
        "print(\"Rendimiento en cross val:\", scores)\n",
        "print(\"Rendimiento overall:\", st.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5980XlBe8r9X",
        "outputId": "d9bdf833-8243-4575-e340-b026f7b6f07e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rendimiento en cross val: [0.95652174 0.98550725 0.97101449 0.98550725 0.97101449 0.95652174\n",
            " 0.98550725 0.98550725 0.95652174 0.94202899 0.98550725 0.97101449\n",
            " 0.98529412 0.94117647 1.         1.         0.97058824 0.95588235\n",
            " 0.95588235 0.98529412]\n",
            "Rendimiento overall: 0.9723145780051151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sup = svm.SVC(kernel='rbf', C=2, random_state=42)\n",
        "scores = cross_val_score(sup, X_data_bank, y_data_bank, cv=20)\n",
        "print(\"Rendimiento en cross val:\", scores)\n",
        "print(\"Rendimiento overall:\", st.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-NT-mqUtw5C",
        "outputId": "09a66012-d732-426e-9c98-7f5dcf21dc22"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rendimiento en cross val: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "Rendimiento overall: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN"
      ],
      "metadata": {
        "id": "n22k4AEm8oID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El método de clasificación K-Nearest Neighbors (KNN) es un algoritmo de aprendizaje supervisado utilizado para clasificar puntos de datos en función de su cercanía a otros puntos vecinos. Para este modelo tenemos los parametros de la cantidad de neighbors, el peso utilizado en la predicción y el algoritmo para computar los neighbors más cercanos. \n",
        "\n",
        "Curiosamente con este modelo la mayoría de hiperparametros generan un rendimiento muy bueno, él que más afecta esto es la cantidad de neighbors. En este primer caso incluso se tiene un muy buen rendimiento con 1 vecindario."
      ],
      "metadata": {
        "id": "I50yDWdP9E8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors = 1, weights=\"distance\", algorithm=\"ball_tree\")\n",
        "scores = cross_val_score(knn, X_data_bank, y_data_bank, cv=20)\n",
        "print(scores)\n",
        "print(st.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hx-3hNUm9acj",
        "outputId": "08714161-b270-463a-e96b-ef85af305e65"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         0.98550725 1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.        ]\n",
            "0.9992753623188406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors = 10, weights=\"uniform\", algorithm=\"kd_tree\")\n",
        "scores = cross_val_score(knn, X_data_bank, y_data_bank, cv=20)\n",
        "print(scores)\n",
        "print(st.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uc0exEY_N7k",
        "outputId": "cc684052-5785-4635-f12b-6d3f8b2c8d87"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors = 2, weights=\"uniform\", algorithm=\"brute\")\n",
        "scores = cross_val_score(knn, X_data_bank, y_data_bank, cv=20)\n",
        "print(scores)\n",
        "print(st.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5O6eVC4uQzZ",
        "outputId": "2be13de1-d2ee-4f17-f87f-cd2e1ee2d62f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perceptron"
      ],
      "metadata": {
        "id": "8BQvnNB__X0O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El perceptrón es un modelo de clasificación de datos linealmente separables, almenos cuando se trata de una capa, así que la eficiencia de este método nos permite concluir si el conjunto de datos es linealmente separable.\n",
        "\n",
        "Los parametros para este modelo son el termino de regularización o penalty, la tolerancia y fit_intercept que es un bool para saber si se debe estimar el intercep. En este caso los mejores para metros son la penalización elasticnet que hace referencia a la norma, calculando el intercept y con una tolerancia de 1e-3."
      ],
      "metadata": {
        "id": "fFzIwm-n_iV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "per = Perceptron(penalty=\"l2\",tol=1e-4,fit_intercept=False, random_state=0)\n",
        "scores = cross_val_score(per, X_data_bank, y_data_bank, cv=100)\n",
        "print(scores)\n",
        "print(st.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpALhmIlv1Us",
        "outputId": "39a1a406-0608-4fd3-b377-fce3b370e436"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.85714286 0.92857143 1.         1.         0.92857143 0.92857143\n",
            " 1.         1.         0.85714286 0.92857143 1.         1.\n",
            " 1.         1.         0.92857143 0.92857143 1.         0.92857143\n",
            " 0.92857143 1.         0.85714286 0.85714286 0.92857143 0.92857143\n",
            " 0.92857143 0.85714286 0.92857143 0.85714286 0.92857143 0.78571429\n",
            " 1.         0.92857143 1.         1.         1.         0.92857143\n",
            " 0.85714286 0.78571429 1.         0.85714286 0.92857143 1.\n",
            " 0.92857143 0.85714286 0.92857143 0.92857143 0.85714286 0.85714286\n",
            " 1.         0.85714286 0.78571429 0.85714286 0.85714286 1.\n",
            " 0.92857143 0.92857143 0.85714286 0.85714286 1.         1.\n",
            " 0.71428571 1.         1.         1.         1.         1.\n",
            " 0.92857143 1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         0.92307692\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         0.92307692 1.         1.         1.         1.\n",
            " 0.92307692 0.84615385 0.92307692 0.84615385 0.84615385 0.84615385\n",
            " 0.84615385 1.         0.84615385 0.92307692]\n",
            "0.9390659340659341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "per = Perceptron(penalty=\"l1\",tol=1e-3, fit_intercept=True, random_state=0)\n",
        "scores = cross_val_score(per, X_data_bank, y_data_bank, cv=100)\n",
        "print(scores)\n",
        "print(st.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFRx_WbqA3pN",
        "outputId": "85b261ea-59c0-4bd8-d8c6-a294a208e35e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.92857143 1.         0.92857143 1.         1.         0.85714286\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 0.92857143 1.         1.         1.         1.         1.\n",
            " 0.85714286 0.92857143 0.92857143 0.85714286 1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         0.92857143 1.         0.92857143 0.92857143 1.\n",
            " 1.         0.92857143 0.92857143 0.92857143 1.         1.\n",
            " 1.         1.         1.         0.78571429 1.         1.\n",
            " 1.         0.92857143 1.         1.         1.         1.\n",
            " 0.78571429 0.92857143 1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         0.92307692 1.         1.\n",
            " 1.         1.         1.         0.92307692 1.         0.92307692\n",
            " 0.92307692 1.         1.         1.        ]\n",
            "0.9790659340659341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "per = Perceptron(penalty=\"elasticnet\",tol=1e-7,fit_intercept=True, random_state=0)\n",
        "scores = cross_val_score(per, X_data_bank, y_data_bank, cv=100)\n",
        "print(scores)\n",
        "print(st.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD7FtTvfA4tr",
        "outputId": "c53abb41-30d9-4582-ff82-184832ae5778"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.92857143 1.         0.92857143 1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         0.92857143 1.         0.92857143 1.         0.92857143\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         0.92857143 1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         0.92857143 0.92857143 1.\n",
            " 1.         0.92857143 0.92857143 1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         0.92857143 0.92857143 1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         0.92307692 1.         1.         1.         1.\n",
            " 1.         1.         1.         0.92307692 1.         1.\n",
            " 1.         1.         1.         0.92307692 1.         0.92307692\n",
            " 0.92307692 1.         1.         1.        ]\n",
            "0.9875824175824176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic"
      ],
      "metadata": {
        "id": "N_u94ncXENWx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La regresión logística es un algoritmo de aprendizaje supervisado utilizado para problemas de clasificación binaria, es decir, cuando se busca predecir una variable de respuesta que toma dos posibles valores es decir que debería tener un buen desempeño en este caso.\n",
        "\n",
        "En este modelo no podemos realizar demasiados cambios, estamos sujetos a una penalización l2, y una formulación primal y punicamente el parametro de regularización afecta el resultado, los demás cambios perjudican el modelo radicalmente."
      ],
      "metadata": {
        "id": "3mqelrWwERlg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log = LogisticRegression(penalty=\"l2\",dual=False, C=1,random_state=0)\n",
        "scores = cross_val_score(log, X_data_bank, y_data_bank, cv=100)\n",
        "print(scores)\n",
        "print(st.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRjyXlcTwznp",
        "outputId": "145e55da-1186-4ef1-d315-ff5cd244078c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.92857143 1.         0.92857143 1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 0.92857143 1.         1.         1.         1.         1.\n",
            " 1.         1.         0.92857143 1.         1.         1.\n",
            " 0.92857143 1.         1.         1.         1.         1.\n",
            " 1.         0.92857143 1.         0.92857143 0.92857143 1.\n",
            " 1.         0.92857143 0.92857143 1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         0.92857143 1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         0.92307692 1.         1.\n",
            " 1.         1.         1.         0.92307692 1.         0.92307692\n",
            " 1.         1.         1.         1.        ]\n",
            "0.9898351648351649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log = LogisticRegression(penalty=\"l2\",dual=False, C=20,random_state=0)\n",
        "scores = cross_val_score(log, X_data_bank, y_data_bank, cv=100)\n",
        "print(scores)\n",
        "print(st.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukkgAA3gFFaL",
        "outputId": "87e8217c-f180-4783-d554-063ffb72d4f5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.92857143 1.         0.92857143 1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 0.92857143 1.         1.         1.         1.         1.\n",
            " 0.92857143 1.         0.92857143 1.         1.         1.\n",
            " 0.92857143 1.         1.         1.         1.         1.\n",
            " 1.         0.92857143 1.         0.92857143 0.92857143 1.\n",
            " 1.         0.92857143 0.92857143 1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         0.92857143 0.92857143 1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         0.92307692 1.         1.\n",
            " 1.         1.         1.         0.92307692 1.         0.92307692\n",
            " 1.         1.         1.         1.        ]\n",
            "0.9884065934065934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusión primer modelo"
      ],
      "metadata": {
        "id": "x9i2rMzF5_Cj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El rendimiento para este primer Dataset es bastante bueno en todos los modelos en general, sin embargo se deben destacar los modelo de SVM con RBF y el de KNN. Pues muestran resultados perfectos en ambos casos."
      ],
      "metadata": {
        "id": "O82Cs0lU6HB6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelos para el segundo Dataset"
      ],
      "metadata": {
        "id": "6pu_N_hByB9x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM"
      ],
      "metadata": {
        "id": "hxvGTgeBG3sP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para el modelo de support vector machine contamos con el hiperparametro de regulación C, el kernel utilizado en el algoritmo, y un parametro que baraja los datos de forma aleatoria. \n",
        "\n",
        "Para elegir el mejor valor de \"C\" se utilizó prueba y error, buscano entre los enteros del 1 al 9.\n",
        "\n",
        "En el caso del kernel, el algoritmo con el mejor rendimiento fue entre \"poly\" y \"linear\", siendo linear el mejor kernel aunque el entrenamiento de este método es mucho más demorado."
      ],
      "metadata": {
        "id": "PIWor310G582"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sup2 = svm.SVC(kernel='linear', C=1, random_state=42)\n",
        "scores = cross_val_score(sup2, occupancy_X, occupancy_y, cv=5)\n",
        "print(scores)\n",
        "print(st.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDY5fWPmyFNr",
        "outputId": "651d6782-abf5-415e-f7af-fff5889f7eb3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.97811284 0.99829767 0.98321984 0.99197471 0.99246109]\n",
            "0.9888132295719845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sup2 = svm.SVC(kernel='poly',degree=3, C=2, random_state=42)\n",
        "scores = cross_val_score(sup2, occupancy_X, occupancy_y, cv=5)\n",
        "print(scores)\n",
        "print(st.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1uOszbXHJ5S",
        "outputId": "d76b8cf9-8cd2-4592-e6e5-1cfbe82cf021"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.97811284 0.99708171 0.98273346 0.99294747 0.99002918]\n",
            "0.9881809338521401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sup2 = svm.SVC(kernel='rbf', C=3, random_state=42)\n",
        "scores = cross_val_score(sup2, occupancy_X, occupancy_y, cv=5)\n",
        "print(scores)\n",
        "print(st.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Df57FVY9HKMW",
        "outputId": "8cac00b2-6c5a-45b8-ea77-dc6d886ddf12"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.96449416 0.99878405 0.98078794 0.99270428 0.99124514]\n",
            "0.985603112840467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN"
      ],
      "metadata": {
        "id": "J-mNPU_AG7Q2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El método de clasificación K-Nearest Neighbors (KNN) es un algoritmo de aprendizaje supervisado utilizado para clasificar puntos de datos en función de su cercanía a otros puntos vecinos. Para este modelo tenemos los parametros de la cantidad de neighbors, el peso utilizado en la predicción y el algoritmo para computar los neighbors más cercanos. \n",
        "\n",
        "En este modelo importa aún más la cantidad de vecindades, así que iterando por los valores de entre 1 a 100 estos valores reflejan el mejor comportamiento, el peso uniforme refleja tambien un mejor rendimiento y además el algoritmo kd_tree."
      ],
      "metadata": {
        "id": "eNr3UJfVItCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn2 = KNeighborsClassifier(n_neighbors = 13, weights=\"distance\", algorithm=\"ball_tree\")\n",
        "scores = cross_val_score(knn2, occupancy_X, occupancy_y, cv=100)\n",
        "print(scores)\n",
        "print(st.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGRyJKMU1qkN",
        "outputId": "7c76aee8-5a5a-4f55-ec3e-204244569c28"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.98058252 0.99514563 1.         1.         1.         0.68932039\n",
            " 1.         0.99029126 1.         1.         0.94660194 0.9368932\n",
            " 1.         0.99514563 1.         1.         1.         0.97087379\n",
            " 0.88349515 1.         1.         1.         1.         0.99514563\n",
            " 0.99029126 1.         1.         1.         1.         0.99514563\n",
            " 1.         1.         1.         1.         0.96601942 1.\n",
            " 1.         1.         1.         1.         0.85436893 1.\n",
            " 0.99029126 1.         1.         0.95145631 0.97572816 0.95145631\n",
            " 1.         1.         1.         0.90776699 0.98543689 0.97572816\n",
            " 0.96601942 1.         0.97572816 0.98058252 1.         1.\n",
            " 0.9902439  1.         1.         0.9902439  0.90243902 1.\n",
            " 0.9902439  0.96097561 1.         1.         1.         0.93658537\n",
            " 1.         1.         1.         1.         0.97560976 1.\n",
            " 0.9902439  0.99512195 0.96585366 1.         1.         1.\n",
            " 1.         1.         1.         1.         0.89756098 1.\n",
            " 1.         1.         1.         0.99512195 0.97073171 1.\n",
            " 1.         1.         1.         1.        ]\n",
            "0.984104901728629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn2 = KNeighborsClassifier(n_neighbors = 25, weights=\"uniform\", algorithm=\"kd_tree\")\n",
        "scores = cross_val_score(knn2, occupancy_X, occupancy_y, cv=100)\n",
        "print(scores)\n",
        "print(st.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGePNwbvIwBy",
        "outputId": "ad0438a6-b95d-4405-f7ac-9f55a1d7efbc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.99514563 1.         1.         1.         1.         0.68932039\n",
            " 1.         1.         1.         1.         0.94660194 0.95145631\n",
            " 1.         1.         1.         1.         1.         0.97572816\n",
            " 1.         1.         1.         1.         1.         0.99514563\n",
            " 1.         1.         1.         1.         1.         0.99514563\n",
            " 1.         1.         1.         1.         0.98058252 1.\n",
            " 1.         1.         1.         1.         0.8592233  1.\n",
            " 1.         1.         1.         0.94660194 0.97572816 1.\n",
            " 1.         1.         1.         0.90776699 0.99514563 1.\n",
            " 1.         1.         0.98058252 0.98543689 1.         1.\n",
            " 0.9902439  1.         1.         0.9902439  0.90243902 1.\n",
            " 0.9902439  0.9902439  1.         1.         1.         0.98536585\n",
            " 1.         1.         1.         1.         0.99512195 1.\n",
            " 1.         0.99512195 0.92195122 1.         1.         1.\n",
            " 1.         1.         1.         1.         0.93658537 1.\n",
            " 1.         1.         1.         0.99512195 0.97073171 1.\n",
            " 1.         1.         1.         1.        ]\n",
            "0.9884302628463177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn2 = KNeighborsClassifier(n_neighbors = 50, weights=\"uniform\", algorithm=\"brute\")\n",
        "scores = cross_val_score(knn2, occupancy_X, occupancy_y, cv=100)\n",
        "print(scores)\n",
        "print(st.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jifBWfnSIwMh",
        "outputId": "d923a60e-5ab0-4991-bfad-f7fef7511b5d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.99514563 1.         1.         1.         1.         0.68932039\n",
            " 0.99514563 1.         1.         1.         0.94660194 0.96116505\n",
            " 1.         1.         1.         1.         1.         0.97572816\n",
            " 1.         1.         1.         1.         1.         0.99514563\n",
            " 1.         1.         1.         1.         1.         0.99514563\n",
            " 1.         1.         1.         1.         0.98058252 1.\n",
            " 1.         1.         1.         1.         0.86893204 1.\n",
            " 1.         1.         1.         0.94660194 0.97572816 1.\n",
            " 1.         1.         1.         0.90776699 0.99514563 1.\n",
            " 1.         1.         0.98058252 0.98058252 1.         1.\n",
            " 0.9902439  1.         1.         0.9902439  0.90243902 1.\n",
            " 0.9902439  1.         1.         1.         1.         0.98536585\n",
            " 1.         1.         1.         1.         0.99512195 1.\n",
            " 1.         0.9902439  0.87317073 1.         1.         1.\n",
            " 1.         1.         1.         1.         0.94146341 1.\n",
            " 1.         1.         1.         0.99512195 0.97073171 1.\n",
            " 1.         1.         1.         1.        ]\n",
            "0.9881371063225195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Perceptron"
      ],
      "metadata": {
        "id": "PA16GC1XG-g3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El perceptrón es un modelo de clasificación de datos linealmente separables, almenos cuando se trata de una capa, así que la eficiencia de este método nos permite concluir si el conjunto de datos es linealmente separable.\n",
        "\n",
        "Los parametros para este modelo son el termino de regularización o penalty, la tolerancia y fit_intercept que es un bool para saber si se debe estimar el intercep. En este caso los mejores para metros son la penalización l1 que hace referencia a la norma, calculando el intercept y con una tolerancia de 1e-3."
      ],
      "metadata": {
        "id": "gv8OmLcFJ9Ib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "per2 = Perceptron(penalty=\"l2\",tol=1e-3, fit_intercept=False, random_state=0)\n",
        "scores = cross_val_score(per2, occupancy_X, occupancy_y, cv=100)\n",
        "print(scores)\n",
        "print(st.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuA2TCK02W2T",
        "outputId": "95360aa6-8e55-4209-f53f-efbfedc7a3e8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.         0.76699029 0.99514563 1.         1.         0.68932039\n",
            " 1.         1.         1.         1.         0.70873786 0.88834951\n",
            " 0.76699029 1.         1.         1.         0.95145631 0.23300971\n",
            " 0.65533981 1.         1.         1.         0.76699029 1.\n",
            " 0.98058252 1.         0.99514563 0.5631068  1.         0.76699029\n",
            " 1.         0.76699029 0.76699029 0.76699029 0.77669903 0.76699029\n",
            " 1.         1.         1.         1.         0.87378641 1.\n",
            " 1.         0.76699029 1.         0.94660194 0.97087379 1.\n",
            " 1.         1.         0.77184466 0.90776699 1.         1.\n",
            " 1.         1.         0.76699029 0.98058252 0.99514563 1.\n",
            " 1.         1.         1.         1.         0.8097561  1.\n",
            " 1.         1.         1.         1.         1.         0.95609756\n",
            " 1.         1.         1.         1.         0.99512195 0.77073171\n",
            " 1.         0.93170732 0.4        1.         1.         1.\n",
            " 1.         1.         1.         1.         0.94146341 1.\n",
            " 1.         1.         1.         0.99512195 0.97073171 0.77073171\n",
            " 1.         0.22926829 0.77073171 0.8097561 ]\n",
            "0.9190461757044754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "per2 = Perceptron(penalty=\"l1\",tol=1e-3, fit_intercept=True, random_state=0)\n",
        "scores = cross_val_score(per2, occupancy_X, occupancy_y, cv=100)\n",
        "print(scores)\n",
        "print(st.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0eHW-z2KBJO",
        "outputId": "3b678da2-aa45-4a4d-fe36-50b3229137fa"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.         1.         1.         1.         1.         0.68932039\n",
            " 0.94174757 1.         1.         1.         0.94660194 0.96601942\n",
            " 1.         1.         1.         1.         1.         0.41262136\n",
            " 1.         1.         1.         1.         1.         0.99514563\n",
            " 1.         1.         1.         1.         1.         0.76699029\n",
            " 1.         0.76699029 1.         0.76699029 0.98543689 0.88349515\n",
            " 1.         1.         1.         1.         0.87864078 1.\n",
            " 1.         1.         1.         0.95145631 0.97572816 1.\n",
            " 1.         1.         1.         0.90776699 0.99514563 1.\n",
            " 1.         1.         0.98058252 0.83980583 0.77184466 1.\n",
            " 0.99512195 1.         1.         0.9902439  0.90243902 1.\n",
            " 0.9902439  1.         1.         1.         1.         0.97560976\n",
            " 1.         1.         1.         1.         0.99512195 1.\n",
            " 1.         1.         0.8195122  1.         1.         1.\n",
            " 1.         1.         1.         1.         0.93658537 1.\n",
            " 1.         1.         1.         0.99512195 0.97073171 1.\n",
            " 0.8195122  0.9902439  1.         0.99512195]\n",
            "0.9679793985318494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "per2 = Perceptron(penalty=\"elasticnet\",tol=1e-7,fit_intercept=True, random_state=0)\n",
        "scores = cross_val_score(per2, occupancy_X, occupancy_y, cv=100)\n",
        "print(scores)\n",
        "print(st.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qcxpAuKKEs6",
        "outputId": "c36e2300-2533-4ec3-fc03-3914a6b9e066"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.         1.         1.         1.         1.         0.54368932\n",
            " 1.         1.         0.76699029 1.         0.88349515 0.96601942\n",
            " 1.         1.         1.         1.         0.98543689 0.23300971\n",
            " 0.62135922 1.         1.         1.         1.         1.\n",
            " 1.         0.91747573 0.76699029 0.76699029 0.80097087 0.76699029\n",
            " 1.         0.83009709 0.83009709 0.76699029 0.97572816 1.\n",
            " 1.         1.         1.         1.         0.87378641 1.\n",
            " 1.         1.         1.         0.90291262 0.97572816 1.\n",
            " 1.         0.76699029 1.         0.90776699 0.82038835 1.\n",
            " 1.         1.         0.84466019 0.94174757 1.         1.\n",
            " 1.         1.         1.         0.99512195 0.83902439 1.\n",
            " 1.         1.         1.         1.         1.         0.88292683\n",
            " 1.         1.         1.         1.         0.99512195 1.\n",
            " 1.         0.76097561 0.43902439 1.         0.22926829 0.9804878\n",
            " 1.         1.         0.77073171 1.         0.94146341 1.\n",
            " 1.         0.77073171 1.         0.99512195 0.9804878  0.99512195\n",
            " 1.         0.22926829 0.77073171 0.22926829]\n",
            "0.9126118872839214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic"
      ],
      "metadata": {
        "id": "1CYpE8RnHAsm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La regresión logística es un algoritmo de aprendizaje supervisado utilizado para problemas de clasificación binaria, es decir, cuando se busca predecir una variable de respuesta que toma dos posibles valores es decir que debería tener un buen desempeño en este caso.\n",
        "\n",
        "En este modelo no podemos realizar demasiados cambios, estamos sujetos a una penalización l2, y una formulación primal y punicamente el parametro de regularización afecta el resultado, los demás cambios perjudican el modelo radicalmente."
      ],
      "metadata": {
        "id": "O9DlSLX4LvfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log2 = LogisticRegression(penalty=\"l2\",dual=False, C=1,random_state=0)\n",
        "scores = cross_val_score(log2, occupancy_X, occupancy_y, cv=100)\n",
        "print(scores)\n",
        "print(st.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_jrCT4y35EH",
        "outputId": "935a4a22-5a5c-475a-9ea4-9d79f51b9615"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.99514563 1.         1.         1.         1.         0.68932039\n",
            " 0.99029126 1.         1.         1.         0.94660194 0.96601942\n",
            " 1.         1.         1.         1.         1.         0.97572816\n",
            " 1.         1.         1.         1.         1.         0.99514563\n",
            " 1.         1.         1.         0.99514563 1.         0.99514563\n",
            " 1.         1.         1.         1.         0.98543689 1.\n",
            " 1.         1.         1.         1.         0.86893204 1.\n",
            " 1.         1.         1.         0.95145631 0.97572816 1.\n",
            " 1.         1.         1.         0.90776699 0.99514563 1.\n",
            " 1.         1.         0.98058252 0.98543689 1.         1.\n",
            " 0.99512195 1.         1.         0.9902439  0.89756098 1.\n",
            " 0.9902439  1.         1.         1.         1.         0.9804878\n",
            " 1.         1.         1.         1.         0.99512195 1.\n",
            " 1.         0.9804878  0.95121951 1.         1.         1.\n",
            " 1.         1.         1.         1.         0.94634146 1.\n",
            " 1.         1.         1.         0.99512195 0.97073171 1.\n",
            " 1.         1.         1.         1.        ]\n",
            "0.9889171205304286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log2 = LogisticRegression(penalty=\"l2\",dual=False, C=50,random_state=0)\n",
        "scores = cross_val_score(log2, occupancy_X, occupancy_y, cv=100)\n",
        "print(scores)\n",
        "print(st.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgEySLL5L4TQ",
        "outputId": "96572e1c-c400-4f6a-a999-2702ee1a139e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.99514563 1.         1.         1.         1.         0.68932039\n",
            " 0.99029126 1.         1.         1.         0.94660194 0.96601942\n",
            " 1.         1.         1.         1.         1.         0.97572816\n",
            " 1.         1.         1.         1.         1.         0.99514563\n",
            " 1.         1.         1.         0.99514563 1.         0.99514563\n",
            " 1.         1.         1.         1.         0.98543689 1.\n",
            " 1.         1.         1.         1.         0.86893204 1.\n",
            " 1.         1.         1.         0.95145631 0.97572816 1.\n",
            " 1.         1.         1.         0.90776699 0.99514563 1.\n",
            " 1.         1.         0.98058252 0.98543689 1.         1.\n",
            " 0.99512195 1.         1.         0.98536585 0.89756098 1.\n",
            " 0.9902439  1.         1.         1.         1.         0.9804878\n",
            " 1.         1.         1.         1.         0.99512195 1.\n",
            " 1.         0.9804878  0.95121951 1.         1.         1.\n",
            " 1.         1.         1.         1.         0.94146341 1.\n",
            " 1.         1.         1.         0.99512195 0.97073171 1.\n",
            " 1.         1.         1.         1.        ]\n",
            "0.9888195595548188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusión segundo Dataset"
      ],
      "metadata": {
        "id": "LNDqRFlo6cpL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para el segundo Dataset la mayoría de modelos tiene un éxtio del 98%, se destacan en particular SVM y Logistic."
      ],
      "metadata": {
        "id": "thWSQLYG6gYW"
      }
    }
  ]
}